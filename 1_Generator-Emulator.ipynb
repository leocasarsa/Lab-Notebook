{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task\n",
    "\n",
    "For the SIMULATE/ESTIMATE/INFER stuff: Please make a simple Python interface for these 3 capabilities --- as a separate generator_emulator.py interface file --- using the abstract base class module in Python, with method-level documentation. Include a constructor that takes a type specification as input (a dict mapping variable names to type specs, where a type spec is either \"numerical\", \"numerical with a range\", or \"closed-set categorical with a specific # of outcomes).\n",
    "\n",
    "Demonstrate it works by providing 4 implementations, + the test cases that show it's working:\n",
    "\n",
    "- a Naive Bayes implementation in pure Python (that enforces numerical range constraints as a post-processing/rejection step)\n",
    "- a Bayesian naive Bayes implementation in Venture (that uses separate programs to model each column)\n",
    "- a heuristic mixture-model based method that fits the mixture by using k means clustering (mapping discrete values to numbers, or using your favorite hybrid discrete/continuous distance metric), choosing k via crossvalidation-based model selection\n",
    "\n",
    "For INFER, do something simple and heuristic for continuous values: fit a mixture of a very-broad-variance Gaussian and a narrow variance Gaussian (heuristically if you want, or via a Bayesian fit in Venture), and test if the weight on the narrow-variance component is above the given confidence threshold.\n",
    "\n",
    "Provide test cases that show, graphically, that the two naive Bayes implementations work on a couple of representative type signatures (when the true generator is realizable given those hypothesis classes), and another test that shows that if the true generator is realizable under the mixture but not naive bayes (i.e. it has a couple components), the mixture works better given enough data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "- No structure learning here?\n",
    "\n",
    "- How does Naive Bayes work in this scenario?\n",
    "\n",
    "\n",
    "In classification, Naive Bayes is a constrained form of a more general Bayesian network, in which all the variables are conditionally independent conditioned on the class label. In the dataset case, will I have access to a class label? If not, should I consider the following approximation?\n",
    "\n",
    "$$P(x'|X) = \\frac{P(X|x')P(x')}{P(X)} = \\frac{\\Pi_{i} P(x_i|x')P(x')}{P(X)}, $$\n",
    "\n",
    "where $x'$ is the variable I want to predict and $X$ is the collection of observations?  \n",
    "\n",
    "   - What is the form of the data likelihood $P(x_i|x')$?\n",
    "\n",
    "   - Should I use conjugate priors and likelihood, such that the posterior is analytically computable? (at least for the pure Python implementation)\n",
    "    \n",
    "    Hint: There is a Naive Bayes method for Databases in Oracle and by Microsoft. Figure out how that works.\n",
    "        - [http://docs.oracle.com/cd/B28359_01/datamine.111/b28129/algo_nb.htm]\n",
    "        - [https://msdn.microsoft.com/en-us/library/ms174806.aspx]\n",
    "    \n",
    "- How would the Bayesian Naive Bayes work?\n",
    "\n",
    "- What is a type signature, i.e., what does it mean for the true generator to be realizable? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from abc import ABCMeta, abstractmethod\n",
    "import pandas as pd\n",
    "from venture.shortcuts import *\n",
    "\n",
    "class BayesDataset(object):\n",
    "    \"\"\"Abstract Base Class for Simulate/Estimate/Infer functionalities\"\"\"\n",
    "    __metaclass__ = ABCMeta\n",
    "    \n",
    "    @abstractmethod\n",
    "    def __init__ (self, dataset, typeSpec):\n",
    "\n",
    "        self.typeSpec = typeSpec\n",
    "        \"\"\"typeSpec is a dict mapping variable names to type specs.\"\"\"\n",
    "        \n",
    "        self.dataset = pd.read_csv(dataset)\n",
    "        \"\"\"dataset is a table in .csv(?) format.\"\"\"\n",
    "            \n",
    "    @abstractmethod\n",
    "    def Simulate(self, y, queries):\n",
    "        \"\"\" \n",
    "        Generates samples for variable y from the conditional predictive \n",
    "        distribution, conditioned queries.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def Estimate(self):\n",
    "        \"\"\" Estimates the probability that each pair of variables in the dataset are dependent.\"\"\"\n",
    "        \"\"\" Returns a symmetric off-diagonal matrix with dependence probabilities\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def Infer(self, sigma, estimator):\n",
    "        \"\"\"Fills in missing values of the database with a point estimate over its predictive distribution \"\"\"\n",
    "        \"\"\"INPUT: estimator- estimator to be used (such as mean, or mode) (object(?))\n",
    "                     sigma - confidence threshold, under which the missing value is not filled. \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NaiveBDS(BayesDataset):\n",
    "    \"\"\"a Naive Bayes implementation in pure Python \n",
    "    (that enforces numerical range constraints as a post-processing/rejection step\"\"\"\n",
    "    pass\n",
    "\n",
    "class BayesNaiveBDS(BayesDataset):\n",
    "    \"\"\"a Bayesian naive Bayes implementation in Venture \n",
    "    (that uses separate programs to model each column)\"\"\"\n",
    "    pass\n",
    "\n",
    "class MixtureBDS(BayesDataset):\n",
    "    \"\"\"a heuristic mixture-model based method that fits the mixture by using k means clustering\n",
    "    (mapping discrete values to numbers, or using your favorite hybrid discrete/continuous distance metric),\n",
    "    choosing k via crossvalidation-based model selection\"\"\"\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
